{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5wGXOisOwef"
      },
      "outputs": [],
      "source": [
        "# add dense layer\n",
        "# balance\n",
        "EPOCHS = 50\n",
        "NBINS = 2\n",
        "BATCH_SIZE = 64\n",
        "SEQ_SIZE = 100\n",
        "EMB_SIZE = 256\n",
        "LSTM_SIZE = 128\n",
        "HIDDEN_SIZE = 4\n",
        "LR = 0.001\n",
        "RS = 51"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22HXy8MxsDvN",
        "outputId": "0cbdadc3-8130-474a-e7da-b6f08a4cf818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeLD8NkrsLqs",
        "outputId": "04234b73-b8e0-4d37-8f11-5421f15b3fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0    21445\n",
            "1.0     2416\n",
            "Name: inmuseum, dtype: int64\n",
            "1.0    2416\n",
            "0.0    2416\n",
            "Name: inmuseum, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "df = pd.read_json(\"gdrive/MyDrive/data/models/painters/allpainters.json\").T\n",
        "# df = df.sample(500)\n",
        "df = df[[\"desc\", \"nbmuseum\"]]\n",
        "df[\"nbmuseum\"] = df.nbmuseum.apply(lambda x: int(x))\n",
        "df[\"inmuseum\"] = df.nbmuseum > 0\n",
        "df[\"inmuseum\"] = df.inmuseum.apply(lambda x: float(x))\n",
        "print(df.inmuseum.value_counts())\n",
        "dfp=df[df.inmuseum==1.0]\n",
        "dfn=df[df.inmuseum==0.0].sample(len(dfp), random_state=RS)\n",
        "df=pd.concat([dfp,dfn])\n",
        "print(df.inmuseum.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jDBrxea6Fti",
        "outputId": "cb198b84-574a-4e11-fa4d-61ecd266586d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       ...,\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "import numpy as np\n",
        "\n",
        "# est = KBinsDiscretizer(n_bins=NBINS, encode='ordinal', strategy=\"kmeans\")\n",
        "# ndf=pd.DataFrame()\n",
        "\n",
        "X = np.array(df.desc)\n",
        "# df[\"inmuseum\"] = est.fit_transform(df.gross.to_frame())\n",
        "y = pd.get_dummies(df.inmuseum).apply(lambda x: np.array(x)).values\n",
        "\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB8DX4fp-kh3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=RS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOBlPoaj7sZ1",
        "outputId": "a340ff80-89a7-4951-e1a9-c3f41d745c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the new vocab is 2683\n",
            "The index of 'painting' is 127\n",
            "The token at index 123 is artists\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "counter = Counter()\n",
        "for text in X_train:\n",
        "  counter.update(tokenizer(text))\n",
        "voc = vocab(counter, min_freq=10, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))\n",
        "voc.set_default_index(voc['<unk>'])\n",
        "\n",
        "print(\"The length of the new vocab is\", len(voc))\n",
        "print(\"The index of 'painting' is\", voc['painting'])\n",
        "print(\"The token at index 123 is\", voc.get_itos()[123])\n",
        "\n",
        "torch.save(voc, f\"gdrive/MyDrive/data/models/painters/voc_{len(voc)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtIbshk9VdAf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.nn.functional import pad\n",
        "import math\n",
        "\n",
        "class PainterDataset(Dataset):\n",
        "    def __init__(self, X, y, vocab, tokenizer, text_size):\n",
        "        self.labels = y\n",
        "        self.texts = X\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text_size = text_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        t = torch.tensor(self.vocab(self.tokenizer(self.texts[idx])))\n",
        "        if len(t) < self.text_size: t=pad(t,(0,self.text_size-len(t)))\n",
        "        if len(t) > self.text_size: t=t[:self.text_size]\n",
        "        return t, torch.tensor(self.labels[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0XegRYmbWT1"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "traindata = PainterDataset(X_train, y_train, voc, tokenizer, SEQ_SIZE)\n",
        "testdata = PainterDataset(X_test, y_test, voc, tokenizer, SEQ_SIZE)\n",
        "\n",
        "train_loader = DataLoader(traindata, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(testdata, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5jktHYkRVp7"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self,voc_size,emb_size,lstm_size,hidden_size,output_size):\n",
        "        super(MyModel,self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=voc_size,embedding_dim=emb_size)\n",
        "        self.lstm = nn.LSTM(emb_size,lstm_size,bidirectional=True,batch_first=True)\n",
        "        # mean and max pooling in both directions => *4\n",
        "        self.hidden = nn.Linear(lstm_size*4,hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out  = nn.Linear(hidden_size, output_size)\n",
        "        self.sm = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embedding(x)\n",
        "        x,_ = self.lstm(x)\n",
        "        avg_pool = torch.mean(x,1)\n",
        "        max_pool,_ = torch.max(x,1)\n",
        "        out = torch.cat((avg_pool,max_pool),1)\n",
        "        out = self.hidden(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.out(out)\n",
        "        out = self.sm(out)\n",
        "        return out\n",
        "\n",
        "    def embs(self,x):\n",
        "      return self.embedding(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2GdcufXTQ9G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def train(data_loader,model,optimizer):\n",
        "    final_predictions = []\n",
        "    final_targets = []\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "    for description,targets in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(description) # float??\n",
        "        # for i,c in enumerate(predictions):\n",
        "        #   for cc in c: print(float(cc), end=\" \")\n",
        "        #   print()\n",
        "        #   for cc in targets[i]:\n",
        "        #     print(float(cc), end=\" \")\n",
        "        #   print()\n",
        "        loss = criterion(predictions,targets.float()) # check\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        predictions = predictions.detach().cpu().numpy().tolist()\n",
        "        targets = targets.detach().cpu().numpy().tolist()\n",
        "        final_predictions.extend(predictions)\n",
        "        final_targets.extend(targets)\n",
        "    return final_predictions,final_targets\n",
        "\n",
        "def evaluate(data_loader,model):\n",
        "  with torch.no_grad():\n",
        "    final_predictions = []\n",
        "    final_targets = []\n",
        "    model.eval()\n",
        "    for description,targets in data_loader:\n",
        "        predictions = model(description)\n",
        "        predictions = predictions.detach().cpu().numpy().tolist()\n",
        "        targets = targets.detach().cpu().numpy().tolist()\n",
        "        final_predictions.extend(predictions)\n",
        "        final_targets.extend(targets)\n",
        "    return final_predictions,final_targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1U81w9PUfdi",
        "outputId": "1496bc17-f188-4f78-f3ef-e772a06292ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   0,    0,    4,  139,  241,    0,   21,    0,    0,  916,  206,   21,\n",
            "         728,   26,  181,    5,    6,   66,  260,    9,   61,    9,   19,   17,\n",
            "         137,   19,    0,   10,    0,  704,   26,    0,    0,   26,    6,    7,\n",
            "           9,   21,    0,   26,  156,   41,  459,   96,    7, 1683,   19,   17,\n",
            "         247,   19,    0,    0,   10,    0,   49,    7, 1619, 1287, 2062,    0,\n",
            "          21,  728,   26,   61, 1088,   47,   57,    7,  127,    0,   26,  620,\n",
            "        1716,   47,   21,   17,  638,   57, 1687,    0,    0,   10,   21, 2348,\n",
            "          26,   41,  582,    7,  119,   69,  161,   20,   54,   17,    0,   87,\n",
            "          69,  557,    0,   19])\n",
            "tensor([[ 1.3280,  1.3864,  1.4667,  ..., -0.3152,  2.5433, -1.7031],\n",
            "        [ 1.3280,  1.3864,  1.4667,  ..., -0.3152,  2.5433, -1.7031],\n",
            "        [ 0.8225, -0.9836,  0.9226,  ..., -0.2233,  2.3221,  0.5981],\n",
            "        ...,\n",
            "        [ 1.5412, -0.5212,  0.8850,  ..., -0.9201, -0.7455, -0.0340],\n",
            "        [ 1.3280,  1.3864,  1.4667,  ..., -0.3152,  2.5433, -1.7031],\n",
            "        [-0.3249,  1.7281, -0.3098,  ..., -0.1483,  0.3548, -0.1080]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = MyModel(len(voc), EMB_SIZE, LSTM_SIZE, HIDDEN_SIZE, NBINS)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = LR)\n",
        "\n",
        "test_text = next(iter(train_loader))[0][0]\n",
        "print(test_text)\n",
        "print(model.embedding(test_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1kMn_7RaS1_",
        "outputId": "ac36d888-2909-4a80-8e6d-d15f30078a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (embedding): Embedding(2683, 256)\n",
            "  (lstm): LSTM(256, 128, batch_first=True, bidirectional=True)\n",
            "  (hidden): Linear(in_features=512, out_features=4, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (out): Linear(in_features=4, out_features=2, bias=True)\n",
            "  (sm): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "print(model)\n",
        "init_model = copy.deepcopy(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "fqHaYy_dUDop",
        "outputId": "73f23ac0-3cfc-479a-f28b-39a7b8e3009d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traning model\n",
            "1 (18980ms): Accuracy Score: 0.6254526642524573/0.6232669557304213 (0.58364953432218/0.5834066325301835)\n",
            "2 (18066ms): Accuracy Score: 0.6968442834971547/0.695619613511054 (0.7054156605726113/0.7052517922605568)\n",
            "3 (21848ms): Accuracy Score: 0.7097775478530781/0.7096231465124994 (0.7640565712314591/0.764270972851691)\n",
            "4 (26903ms): Accuracy Score: 0.7139161924469736/0.7141807183769606 (0.8220075888237324/0.8222158918370397)\n",
            "5 (19658ms): Accuracy Score: 0.7263321262286602/0.7253872919008618 (0.8682304242842359/0.8683755850846606)\n",
            "6 (20628ms): Accuracy Score: 0.7128815312984997/0.7130458754884642 (0.9220420834770611/0.9221284087696302)\n",
            "7 (19704ms): Accuracy Score: 0.7159855147439214/0.7157951929768214 (0.9565367368057951/0.9565554708331072)\n",
            "8 (20270ms): Accuracy Score: 0.7056389032591827/0.7053749799261282 (0.9782683684028975/0.9782372780676427)\n",
            "9 (20878ms): Accuracy Score: 0.7046042421107087/0.7040035330014454 (0.985857192135219/0.9858142255654272)\n",
            "10 (20456ms): Accuracy Score: 0.7102948784273151/0.7098083614367539 (0.9875819248016557/0.9875329489409218)\n",
            "11 (20488ms): Accuracy Score: 0.7015002586652871/0.7006445051121459 (0.9886167644015178/0.9885698469950661)\n",
            "12 (19212ms): Accuracy Score: 0.7015002586652871/0.7005080027835768 (0.9899965505346672/0.9899415891075489)\n",
            "13 (19964ms): Accuracy Score: 0.7097775478530781/0.709195439216316 (0.9899965505346672/0.9899375433726578)\n",
            "14 (19018ms): Accuracy Score: 0.7061562338334195/0.7051142872437235 (0.9906864436012418/0.9906355516335725)\n",
            "15 (19790ms): Accuracy Score: 0.7082255561303673/0.7078298806273754 (0.9910313901345291/0.9909784871616933)\n",
            "16 (20721ms): Accuracy Score: 0.7102948784273151/0.7096627589529468 (0.9913763366678164/0.9913295141595961)\n",
            "17 (19437ms): Accuracy Score: 0.7046042421107087/0.7038033295862105 (0.9917212832011039/0.9916724496877168)\n",
            "18 (18448ms): Accuracy Score: 0.7009829280910502/0.7004410898774156 (0.9913763366678164/0.991325468424705)\n",
            "19 (19305ms): Accuracy Score: 0.7082255561303673/0.7078389807826133 (0.9913763366678164/0.991325468424705)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2de76f2ad3a9>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtoutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mttargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbaccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtaccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbtaccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mttargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-0202fa9034c9>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data_loader, model)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-e4127f3d10c9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mavg_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mmax_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "import time\n",
        "\n",
        "def acc(t,p):\n",
        "  tt = []\n",
        "  pp = []\n",
        "  for i,v in enumerate(t):\n",
        "    tt.append(np.argmax(v))\n",
        "    pp.append(np.argmax(p[i]))\n",
        "  return metrics.accuracy_score(tt,pp), metrics.balanced_accuracy_score(tt,pp)\n",
        "\n",
        "print(\"Traning model\")\n",
        "best_va = {\"accuracy\": 0, \"model\": None, \"epoch\": 0}\n",
        "best_ta = {\"accuracy\": 0, \"model\": None, \"epoch\": 0}\n",
        "best_ba = {\"accuracy\": 0, \"model\": None, \"epoch\": 0}\n",
        "for epoch in range(1,EPOCHS+1):\n",
        "        t = time.time()\n",
        "        toutputs,ttargets = train(train_loader,model,optimizer)\n",
        "        outputs,targets = evaluate(test_loader,model)\n",
        "        accuracy,baccuracy = acc(targets,outputs)\n",
        "        taccuracy,btaccuracy = acc(ttargets,toutputs)\n",
        "        print(f\"{epoch} ({round((time.time()-t)*1000)}ms): Accuracy Score: {accuracy}/{baccuracy} ({taccuracy}/{btaccuracy})\")\n",
        "        if accuracy>best_va[\"accuracy\"]:\n",
        "            best_va[\"accuracy\"] = accuracy\n",
        "            best_va[\"model\"] = copy.deepcopy(model.state_dict())\n",
        "            best_va[\"epoch\"] = epoch\n",
        "        if taccuracy>best_ta[\"accuracy\"]:\n",
        "            best_ta[\"accuracy\"] = taccuracy\n",
        "            best_ta[\"model\"] = copy.deepcopy(model.state_dict())\n",
        "            best_ta[\"epoch\"] = epoch\n",
        "        if baccuracy>best_ba[\"accuracy\"]:\n",
        "            best_ba[\"accuracy\"] = baccuracy\n",
        "            best_ba[\"model\"] = copy.deepcopy(model.state_dict())\n",
        "            best_ba[\"epoch\"] = epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-RXSFpvTxk-",
        "outputId": "bf8b1dbf-3412-4e65-ca73-784bd6ae8238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7263321262286602 5\n",
            "0.9917212832011039 17\n",
            "0.7253872919008618 5\n"
          ]
        }
      ],
      "source": [
        "print(best_va[\"accuracy\"], best_va[\"epoch\"])\n",
        "print(best_ta[\"accuracy\"], best_ta[\"epoch\"])\n",
        "print(best_ba[\"accuracy\"], best_ba[\"epoch\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz6WNZzaQ-T8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.save(best_va[\"model\"], f\"gdrive/MyDrive/data/models/painters/model_sd_NB{NBINS}_E{best_va['epoch']}_RS{RS}_BS{BATCH_SIZE}_LR{LR}_V{len(voc)}_{SEQ_SIZE}x{EMB_SIZE}x{LSTM_SIZE}x{HIDDEN_SIZE}_VA{best_va['accuracy']}\")\n",
        "torch.save(best_ta[\"model\"], f\"gdrive/MyDrive/data/models/painters/model_sd_NB{NBINS}_E{best_ta['epoch']}_RS{RS}_BS{BATCH_SIZE}_LR{LR}_V{len(voc)}_{SEQ_SIZE}x{EMB_SIZE}x{LSTM_SIZE}x{HIDDEN_SIZE}_TA{best_ta['accuracy']}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}