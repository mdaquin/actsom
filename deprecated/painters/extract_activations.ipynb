{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# add dense layer\n",
        "# balance\n",
        "EPOCHS = 50\n",
        "NBINS = 2\n",
        "BATCH_SIZE = 32\n",
        "SEQ_SIZE = 100\n",
        "EMB_SIZE = 256\n",
        "LSTM_SIZE = 128\n",
        "HIDDEN_SIZE = 4\n",
        "LR = 0.001\n",
        "RS = 51\n",
        "V = 2683"
      ],
      "metadata": {
        "id": "aXzdobHLrQNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4Dx3q0RrTw5",
        "outputId": "4dccaad1-6ced-4cd8-d105-432e5b34c9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "df = pd.read_json(\"gdrive/MyDrive/data/models/painters/allpainters.json\").T\n",
        "# df = df.sample(500)\n",
        "df = df[[\"desc\", \"nbmuseum\"]]\n",
        "df[\"nbmuseum\"] = df.nbmuseum.apply(lambda x: int(x))\n",
        "df[\"inmuseum\"] = df.nbmuseum > 0\n",
        "df[\"inmuseum\"] = df.inmuseum.apply(lambda x: float(x))\n",
        "print(df.inmuseum.value_counts())\n",
        "dfp=df[df.inmuseum==1.0]\n",
        "dfn=df[df.inmuseum==0.0].sample(len(dfp), random_state=RS)\n",
        "df=pd.concat([dfp,dfn])\n",
        "print(df.inmuseum.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veFNTbQ4rUfl",
        "outputId": "41f59a41-ed65-4c53-ae4c-36be64e8f4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0    21445\n",
            "1.0     2416\n",
            "Name: inmuseum, dtype: int64\n",
            "1.0    2416\n",
            "0.0    2416\n",
            "Name: inmuseum, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "import numpy as np\n",
        "\n",
        "# est = KBinsDiscretizer(n_bins=NBINS, encode='ordinal', strategy=\"kmeans\")\n",
        "# ndf=pd.DataFrame()\n",
        "\n",
        "X = np.array(df.desc)\n",
        "# df[\"inmuseum\"] = est.fit_transform(df.gross.to_frame())\n",
        "y = pd.get_dummies(df.inmuseum).apply(lambda x: np.array(x)).values\n",
        "\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sB2IlXTfTqr",
        "outputId": "fc030f47-e1ec-4e0a-a894-adb75c39678e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [0, 1],\n",
              "       [0, 1],\n",
              "       ...,\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import vocab\n",
        "import torch\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "voc = torch.load(\"gdrive/MyDrive/data/models/painters/voc_2683\")\n",
        "print(\"The length of the new vocab is\", len(voc))\n",
        "print(\"The index of 'film' is\", voc['painting'])\n",
        "print(\"The token at index 123 is\", voc.get_itos()[123])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBblOqhGtJPz",
        "outputId": "d0a1b86c-9df5-4d1d-9559-096260d73794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the new vocab is 2683\n",
            "The index of 'film' is 127\n",
            "The token at index 123 is artists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.nn.functional import pad\n",
        "import math\n",
        "\n",
        "class PainterDataset(Dataset):\n",
        "    def __init__(self, X, y, vocab, tokenizer, text_size):\n",
        "        self.labels = y\n",
        "        self.texts = X\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text_size = text_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        t = torch.tensor(self.vocab(self.tokenizer(self.texts[idx])))\n",
        "        if len(t) < self.text_size: t=pad(t,(0,self.text_size-len(t)))\n",
        "        if len(t) > self.text_size: t=t[:self.text_size]\n",
        "        return t, torch.tensor(self.labels[idx])"
      ],
      "metadata": {
        "id": "pM7kAbHirurG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self,voc_size,emb_size,lstm_size,hidden_size,output_size):\n",
        "        super(MyModel,self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=voc_size,embedding_dim=emb_size)\n",
        "        self.lstm = nn.LSTM(emb_size,lstm_size,bidirectional=True,batch_first=True)\n",
        "        # mean and max pooling in both directions => *4\n",
        "        self.hidden = nn.Linear(lstm_size*4,hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out  = nn.Linear(hidden_size, output_size)\n",
        "        self.sm = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.embedding(x)\n",
        "        x,_ = self.lstm(x)\n",
        "        avg_pool = torch.mean(x,1)\n",
        "        max_pool,_ = torch.max(x,1)\n",
        "        out = torch.cat((avg_pool,max_pool),1)\n",
        "        out = self.hidden(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.out(out)\n",
        "        out = self.sm(out)\n",
        "        return out\n",
        "\n",
        "    def embs(self,x):\n",
        "      return self.embedding(x)"
      ],
      "metadata": {
        "id": "JHtaS5viqw7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRKN1r6nqiX9",
        "outputId": "28772099-627e-4c04-8fc2-98f2d4eebfbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "model = MyModel(len(voc), EMB_SIZE, LSTM_SIZE, HIDDEN_SIZE, NBINS)\n",
        "model.load_state_dict(torch.load(\"gdrive/MyDrive/data/models/painters/model_sd_NB2_E5_RS51_BS64_LR0.001_V2683_100x256x128x4_VA0.7263321262286602\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def get_activation(name):\n",
        "     def hook(model, input, output):\n",
        "         if type(output) != torch.Tensor: activation[name] = output\n",
        "         else: activation[name] = output.detach()\n",
        "     return hook\n",
        "\n",
        "for k in model.__dict__[\"_modules\"]:\n",
        "   getattr(model,k).register_forward_hook(get_activation(k))\n",
        "\n",
        "dataset = PainterDataset(X, y, voc, tokenizer, SEQ_SIZE)\n",
        "\n",
        "class IndexDataset(Dataset):\n",
        "    def __init__(self, originalDataset):\n",
        "        self.dataset = originalDataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "       return self.dataset[idx], idx\n",
        "\n",
        "idataset = IndexDataset(dataset)\n",
        "\n",
        "loader = DataLoader(idataset, batch_size=128)\n",
        "\n",
        "# DOC: Assumes dataset returns a tuple, maybe should have Xs only?\n",
        "actdata = {\"idx\": [], \"targets\": [], \"preds\": [], \"activations\": {}}\n",
        "with torch.no_grad():\n",
        " for d,t in loader:\n",
        "  activation = {}\n",
        "  out = model(d[0])\n",
        "  for i,ut in enumerate(t):\n",
        "    actdata[\"idx\"].append(int(ut))\n",
        "    actdata[\"targets\"].append(d[1][i])\n",
        "    actdata[\"preds\"].append(out[i])\n",
        "    for k in activation:\n",
        "      if type(activation[k]) == torch.Tensor:\n",
        "         if k not in actdata[\"activations\"]: actdata[\"activations\"][k] = []\n",
        "         actdata[\"activations\"][k].append(activation[k][i])\n",
        "      else:\n",
        "         if k not in actdata[\"activations\"]: actdata[\"activations\"][k] = []\n",
        "         actdata[\"activations\"][k].append(activation[k][0][i])\n",
        "for k in actdata[\"activations\"]:\n",
        "  print(k, len(actdata[\"activations\"][k]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrvDRQf6G2TQ",
        "outputId": "5e3447a0-0e8b-44b0-d820-860acc5c10ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding 4832\n",
            "lstm 4832\n",
            "hidden 4832\n",
            "relu 4832\n",
            "out 4832\n",
            "sm 4832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(actdata,\"gdrive/MyDrive/data/models/painters/actdata\")"
      ],
      "metadata": {
        "id": "9qvLaqSaKmaN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}